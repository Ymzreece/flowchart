from __future__ import annotations

import argparse
import json
import os
from pathlib import Path
from typing import Optional

try:
    from openai import OpenAI
except ImportError as exc:  # pragma: no cover - dependency missing at runtime
    raise SystemExit("Missing dependency 'openai'. Install it with `pip install openai`.") from exc


DEFAULT_MODEL = "gpt-5-nano"


SYSTEM_PROMPT = """You are a senior software architect converting prose explanations into a structured flowchart graph.
Given a detailed natural-language walkthrough of a system, extract every major step, branch, loop, and background activity into nodes and edges that describe control flow.
Be thorough: capture each menu option, condition, and repeated process so downstream tooling can render an accurate flowchart."""


OUTPUT_INSTRUCTION = """
Return ONLY JSON matching this schema:
{
  "metadata": {
    "title": "Concise title",
    "summary": "1-2 sentence overview",
    "language": "text"
  },
  "entry_node": "node id",
  "nodes": [
    {
      "id": "unique string id",
      "title": "Short descriptive title",
      "summary": "One-sentence description of this step",
      "detail": "Optional longer explanation (can be null)",
      "type": "start|process|decision|loop|end|io|call"
    }
  ],
  "edges": [
    {
      "source": "node id",
      "target": "node id",
      "label": "Condition, choice, or trigger leading to this transition (optional)"
    }
  ]
}
Guidelines:
- Create a `start` node for the entry point and an `end` node when the flow terminates.
- Represent every distinct branch or menu option with its own node and connect them using edges labelled with the triggering condition or key press.
- Model loops explicitly with nodes of type `loop` and ensure the edges show how the loop repeats and exits.
- Ensure every edge references valid node IDs and the graph is connected from the entry node.
- Do not wrap the JSON in code fences or include commentary.
"""


def build_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(
        description="Convert a natural-language explanation into flowchart JSON using an LLM."
    )
    parser.add_argument(
        "--input",
        type=Path,
        default=Path("../flow_explanation.txt"),
        help="Path to the explanation text generated by flowcode_1 (default: ../flow_explanation.txt).",
    )
    parser.add_argument(
        "--output",
        type=Path,
        default=Path("flowchart.json"),
        help="Where to write the flowchart JSON (default: flowchart.json).",
    )
    parser.add_argument(
        "--model",
        type=str,
        default=DEFAULT_MODEL,
        help=f"LLM model to use (default: {DEFAULT_MODEL}).",
    )
    parser.add_argument(
        "--show-prompt",
        action="store_true",
        help="Print the composed prompt before sending it to the model.",
    )
    return parser


def read_text(path: Path) -> str:
    try:
        return path.read_text(encoding="utf-8")
    except FileNotFoundError:
        raise SystemExit(f"Input file not found: {path}")


def write_json(path: Path, payload: dict) -> None:
    path.write_text(json.dumps(payload, indent=2), encoding="utf-8")
    print(f"Wrote flowchart JSON to {path}")


def call_model(explanation: str, *, model: str, show_prompt: bool) -> dict:
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise SystemExit(
            "Environment variable OPENAI_API_KEY is not set. "
            "Export your API key before running this script."
        )

    client = OpenAI(api_key=api_key)

    prompt = f"{explanation}\n\n{OUTPUT_INSTRUCTION.strip()}"

    if show_prompt:
        print("--- Prompt being sent ---")
        print(prompt)
        print("--------------------------")

    response = client.responses.create(
        model=model,
        instructions=SYSTEM_PROMPT,
        input=prompt,
    )

    if hasattr(response, "output_text"):
        raw = response.output_text  # type: ignore[attr-defined]
    else:
        try:
            raw = response.output[0].content[0].text  # type: ignore[attr-defined]
        except (AttributeError, IndexError, KeyError) as exc:  # pragma: no cover
            raise SystemExit(f"Unexpected API response format: {response}") from exc

    try:
        return json.loads(raw)
    except json.JSONDecodeError as exc:
        raise SystemExit(f"Model did not return valid JSON: {exc}\nRaw output:\n{raw}") from exc


def main(argv: Optional[list[str]] = None) -> None:
    parser = build_parser()
    args = parser.parse_args(argv)

    explanation = read_text(args.input)
    if not explanation.strip():
        raise SystemExit(f"Input file {args.input} is empty.")

    print(f"Using model: {args.model}")
    print(f"Reading explanation from: {args.input}")

    result = call_model(explanation, model=args.model, show_prompt=args.show_prompt)
    write_json(args.output, result)


if __name__ == "__main__":  # pragma: no cover
    main()
